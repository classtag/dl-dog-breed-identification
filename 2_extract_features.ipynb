{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征抽取\n",
    "\n",
    "Gluon中的model_zoo中模型的一般结构都是分为 feature 和 classifier部分。\n",
    "\n",
    "这里使用gluon中已经Pertrained好的network抽取特征，然后再接下来的分类器部分，我们用来组合特征进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from tqdm import tqdm\n",
    "from mxnet import autograd\n",
    "from mxnet.gluon.model_zoo.vision import *\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import os\n",
    "import gc\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 尝试在gpu上运行，cpu也是可以的，只是比较耗时\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义图片增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_augs(shape):\n",
    "    train_augs = [\n",
    "        image.HorizontalFlipAug(.5),\n",
    "        image.RandomCropAug((shape,shape))\n",
    "    ]\n",
    "    valid_augs = train_augs\n",
    "    tests_augs = [\n",
    "        image.CenterCropAug((shape,shape))\n",
    "    ]\n",
    "    return train_augs, valid_augs, tests_augs\n",
    "\n",
    "def transform(data, label, augs):\n",
    "    data = data.astype('float32')\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, nd.array([label]).asscalar().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = gluon.data.DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用gluon中非常好用的 **ImageFolderDataset** 加载数据，实际上就是一个迭代器\n",
    "通过aug支持reshape成network对应需要的input_shape大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_images_data_loader(batch_size, shape):\n",
    "    train_augs, valid_augs, tests_augs = get_augs(shape)\n",
    "    train_imgs = gluon.data.vision.ImageFolderDataset('input/train',transform=lambda X, y: transform(X, y, train_augs))\n",
    "    valid_imgs = gluon.data.vision.ImageFolderDataset('input/valid',transform=lambda X, y: transform(X, y, valid_augs))\n",
    "    tests_imgs = gluon.data.vision.ImageFolderDataset('input/tests',transform=lambda X, y: transform(X, y, tests_augs))\n",
    "    train_data = loader(train_imgs, batch_size, shuffle=True)\n",
    "    valid_data = loader(valid_imgs, batch_size, shuffle=True)\n",
    "    tests_data = loader(tests_imgs, batch_size)\n",
    "    return train_data, valid_data, tests_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_224_data, valid_224_data, tests_224_data = get_images_data_loader(batch_size, 224)\n",
    "train_299_data, valid_299_data, tests_299_data = get_images_data_loader(batch_size, 299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试resnet和densent网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input shape 为224 的网络模型\n",
    "net_224_list = ['resnet18_v2','resnet34_v2', 'resnet50_v2','resnet101_v1', 'resnet152_v1',\n",
    "                'densenet121','densenet161','densenet169','densenet201']\n",
    "# input shape 为299 的网络模型\n",
    "net_299_list = ['inception_v3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个可以通过模型名字获得微调后的模型方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tuning_net(net_name, ctx):\n",
    "    net_function = globals()[net_name] # 动态调用\n",
    "    pretrained_net = net_function(pretrained=True, ctx=ctx)\n",
    "    finetune_net = net_function(classes=120, ctx=ctx)\n",
    "    finetune_net.features = pretrained_net.features\n",
    "    finetune_net.classifier.initialize(init.Xavier())\n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_loader(net_input_shape, data_scope):\n",
    "    '''\n",
    "    通过network的输入shape和数据类型（train,vaild,tests）\n",
    "    '''\n",
    "    return globals()[data_scope + \"_\" + str(net_input_shape) + \"_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面定义从pretrained 网络模型中抽取特征的方法，后边可以重复利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features_by_pretrain_network(net_input_shape, data_scope, rebuild=False):\n",
    "    \n",
    "    net_list = globals()[\"net_%d_list\" % net_input_shape]\n",
    "    for name in net_list:\n",
    "        \n",
    "        features_file_name = \"features/%s_%d_%s_features.h5\" % (name, net_input_shape, data_scope)\n",
    "        labels_file_name = \"features/%d_%s_labels.h5\" % (net_input_shape, data_scope)\n",
    "        \n",
    "        if not rebuild and os.path.exists(features_file_name) and os.path.exists(labels_file_name):\n",
    "            print(\"%s and %s have exsits!\" % (features_file_name, labels_file_name))\n",
    "            continue\n",
    "        \n",
    "        print(\"starting extract features for network:%s, data_scope:%s, input_shape:%d\" % (name, data_scope, net_input_shape))\n",
    "        net = get_tuning_net(name, ctx)\n",
    "        data_loader = get_data_loader(net_input_shape, data_scope)\n",
    "        \n",
    "        features = []\n",
    "        labels = []\n",
    "        for X, y in tqdm(data_loader):\n",
    "            if not os.path.exists(features_file_name):\n",
    "                feature = net.features(X.as_in_context(ctx))\n",
    "                features.append(feature.asnumpy())\n",
    "            if not os.path.exists(labels_file_name):\n",
    "                labels.append(y.asnumpy())\n",
    "        \n",
    "        if len(features) > 0:\n",
    "            print(\"saving features to file: %s\" % features_file_name)\n",
    "            features = np.concatenate(features, axis=0)\n",
    "            with h5py.File(features_file_name, \"w\") as f:\n",
    "                f[\"features\"] = features\n",
    "        \n",
    "        if os.path.exists(labels_file_name):\n",
    "            continue\n",
    "        print(\"saving labels to file: %s\" % labels_file_name)\n",
    "        with h5py.File(labels_file_name, \"w\") as f:\n",
    "            labels = np.concatenate(labels, axis=0)\n",
    "            f[\"labels\"] = labels  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始抽取各个数据的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_features_by_pretrain_network(224, 'train')\n",
    "extract_features_by_pretrain_network(224, 'valid')\n",
    "extract_features_by_pretrain_network(224, 'tests')\n",
    "extract_features_by_pretrain_network(299, 'train')\n",
    "extract_features_by_pretrain_network(299, 'valid')\n",
    "extract_features_by_pretrain_network(299, 'tests')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gluon]",
   "language": "python",
   "name": "conda-env-gluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
