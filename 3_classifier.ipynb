{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "from mxnet import image\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from tqdm import tqdm\n",
    "from mxnet import autograd\n",
    "from mxnet.gluon.model_zoo.vision import *\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import os\n",
    "import gc\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# READ Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(network_name, shape, data_scope, batch_size=32):\n",
    "    features_file_path = \"features/%s_%d_%s_features.h5\" % (network_name,shape,data_scope)\n",
    "    features = None\n",
    "    with h5py.File(features_file_path) as f:\n",
    "        features = np.array(f['features'])\n",
    "    \n",
    "    labels_file_path = \"features/%d_%s_labels.h5\" % (shape,data_scope)\n",
    "    labels = None\n",
    "    with h5py.File(labels_file_path) as f:\n",
    "        labels = np.array(f['labels'])\n",
    "    return gluon.data.DataLoader(gluon.data.ArrayDataset(nd.array(features), nd.array(labels)), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ds = load_dataset('resnet18_v2',224,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 <class 'mxnet.ndarray.ndarray.NDArray'> <class 'mxnet.ndarray.ndarray.NDArray'>\n"
     ]
    }
   ],
   "source": [
    "for features, labels in ds:\n",
    "    labels = labels.as_in_context(mx.gpu())\n",
    "    features = features.as_in_context(mx.gpu())\n",
    "    print(len(labels), type(labels), type(features))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    return nd.mean(nd.argmax(output, axis=1) == labels).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(net, data):\n",
    "    loss, acc, n = 0., 0., 0.\n",
    "    steps = len(data)\n",
    "    for data, label in data:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label)\n",
    "        loss += nd.mean(softmax_cross_entropy(output, label)).asscalar()\n",
    "    return loss/steps, acc/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fit(net, train_data, valid_data, num_epochs=20, learning_rate=1e-4, wd=1e-5, print_batches=None, ctx=mx.gpu()):        \n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    net.hybridize()\n",
    "    \n",
    "    print(\"Start training on \", ctx)\n",
    "    \n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate, 'wd': wd})\n",
    "            \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = .0, .0\n",
    "        steps = len(train_data)\n",
    "        for features, labels in train_data:\n",
    "            features = features.as_in_context(ctx)\n",
    "            labels = labels.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                output = net(features)\n",
    "                loss = softmax_cross_entropy(output, labels)\n",
    "            batch_size =  len(labels)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            train_acc += accuracy(output, labels)\n",
    "        val_loss, val_acc = evaluate(net, valid_data)\n",
    "        print(\"Epoch %d. loss: %.4f, acc: %.2f%%, val_loss %.4f, val_acc %.2f%%\" % \n",
    "              (epoch+1, train_loss/steps, train_acc/steps*100, val_loss, val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_network_classifier(ctx):\n",
    "    num_outputs = 120\n",
    "    net = gluon.nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "#         net.add(gluon.nn.Flatten())\n",
    "        net.add(gluon.nn.Dense(256, activation='relu'))\n",
    "        net.add(gluon.nn.Dropout(0.3))\n",
    "        net.add(gluon.nn.Dense(num_outputs))\n",
    "    net.initialize(ctx=ctx)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(classifier, pretrain_network_name, input_shape):\n",
    "    train_data = load_dataset(pretrain_network_name, input_shape, 'train')\n",
    "    valid_data = load_dataset(pretrain_network_name, input_shape, 'valid')\n",
    "    print(\"train %s\" % pretrain_network_name)\n",
    "    fit(classifier,train_data,valid_data)    \n",
    "    model_file_path = \"models/%s_%d.params\" % (pretrain_network_name, input_shape)\n",
    "    classifier.save_params(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "claasifier = get_network_classifier(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridSequential(\n",
       "  (0): Dense(256, Activation(relu))\n",
       "  (1): Dropout(p = 0.5)\n",
       "  (2): Dense(120, linear)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input shape 为224 的网络模型\n",
    "net_224_list = ['resnet152_v1',\n",
    "                'densenet121','densenet161','densenet169','densenet201']\n",
    "# input shape 为299 的网络模型\n",
    "net_299_list = ['inception_v3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train resnet152_v1\n",
      "Start training on  gpu(0)\n",
      "Epoch 1. loss: 4.7834, acc: 1.24%, val_loss 4.7850, val_acc 1.11%\n",
      "Epoch 2. loss: 4.7831, acc: 1.24%, val_loss 4.7848, val_acc 1.11%\n",
      "Epoch 3. loss: 4.7825, acc: 1.24%, val_loss 4.7846, val_acc 1.11%\n",
      "Epoch 4. loss: 4.7820, acc: 1.24%, val_loss 4.7844, val_acc 1.11%\n",
      "Epoch 5. loss: 4.7816, acc: 1.24%, val_loss 4.7842, val_acc 1.11%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76bd2bd2d365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnetwork_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet_224_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclaasifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-8d8f51484349>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(classifier, pretrain_network_name, input_shape)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_network_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpretrain_network_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"models/%s_%d.params\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpretrain_network_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c511328d3095>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(net, train_data, valid_data, num_epochs, learning_rate, wd, print_batches, ctx)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for network_name in net_224_list:\n",
    "    train(claasifier, network_name, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gluon]",
   "language": "python",
   "name": "conda-env-gluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
